# java-optimization

## 성능과 최적화
### 성능은 실험과학이다.
> 성능은 다음과 같은 활동을 하면서 원하는 결과를 얻기 위한, 일종의 실험과학이라고 볼 수 있다.  
> * 원하는 결과를 정의한다.
> * 기존 시스템을 측정한다.
> * 요건을 충족시키려면 무슨 일을 해야 할지 정한다.
> * 개선 활동을 추진한다.
> * 다시 테스트한다.
> * 목표가 달성됐는지 판단한다. 

### 성능 분류
> **처리율(throughput)**  
> 처리율은 시스템이 수행 가능한 작업 비율을 나타낸 지표이다. 보통 일정 시간 동안 완료한 작업 단위 수로 표시한다.(예: 초당 처리 가능한 트랜잭션 수 TPS)  
> 처리율이 실제 성능을 반영하는 의미 있는 지표가 되려면 수치를 얻은 기준 플랫폼에 대해서도 내용을 기술해야 한다. 
> * 하드웨어 스펙
> * OS
> * 소프트웨어 스택
> * 테스트한 시스템의 환경: 단일/클러스터
> * 워크로드(작업 할당량)
> 
> **지연(latency)**  
> 하나의 트랜잭션을 처리하고 그 결과를 응답받았을 때까지의 소요된 시간.
> 
> **용량(capacity)**  
> 용량은 시스템이 보유한 작업 병렬성의 총량, 즉 시스템이 동시 처리 가능한 작업 단위(즉, 트랜잭션) 개수를 말한다.  
> 
> **사용률(utilization)**  
> 성능 분석 업무 중 가장 흔한 태스크는 시스템 리소스를 효율적으로 활용하는 것이다. 
> 
> **효율(efficiency)**  
> 전체 시스템의 효율은 처리율을 리소스 사용률로 나눈 값으로 측정한다.
> 
> **확장성(scalability)**  
> 처리율이나 시스템 용량은, 처리하는 데 끌어 쓸 수 있는 리소스에 달려 있다. 리소스 추가에 따른 처리율 변화는 시스템/애플리케이션의 확장성을 가늠하는 척도이다.  
> 시스템 확장성은 궁극적으로는 정확히 리소스를 투입한 만큼 처리율이 변경되는 형태를 지향한다.
> 
> **저하(degradation)**  
> 시스템이 더 많은 부하를 받으면 지연 그리고 처리율 측정값에 변화가 생긴다. 시스템을 덜 사용하고 있으면 측정값이 느슨하게 변하지만, 
> 시스템이 풀 가동된 상태면 처리율이 더는 늘어나지 않는, 즉 지연이 증가하는 양상을 띤다. 이런 현상을 부하 증가에 따른 저하라고 한다.  

---

## JVM 이야기
### Hotspot VM 과 JIT(Just In Time) 컴파일러
> **C 언어의 동작 방식**
> C, C++, GoLang, Rust 등과 같은 컴파일 언어는 컴파일 과정에서 바로 기계어로 번역하고 실행 파일을 만들어낸다. 
> 그리고 컴파일 시에 코드 최적화까지 진행하여 처리 성능이 상당히 뛰어나다. 대신 생성된 기계어가 빌드 환경(CPU 아키텍처)에 종속적이라서, 플랫폼이 바뀐다면 다시 빌드해야 하는 문제가 있다.
> 
> **Java 언어의 동작 방식**  
> 자바는 이러한 플랫폼 종속적인 문제를 해결하고자 JVM을 도입하였고, 그래서 동작 과정이 조금 다르다.
> 만약 우리가 자바 애플리케이션을 실행한다고 하면, 자바 코드는 먼저 바이트 코드로 컴파일된다. 바이트 코드는 자바 코드보다 간결하고 간단하지만, 
> 0과 1만 이해할 수 있는 컴퓨터는 이를 읽어들일 수 없다. 바이트 코드는 JVM 을 위한 중간 언어인 것이다. 따라서 JVM 은 애플리케이션이 실행되면서 읽어들인 
> 바이트 코드를 실시간으로 기계어로 번역하고, CPU 가 번역된 기계어를 처리한다. 이러한 구조 덕분에 Java 는 플랫폼에 종속되지 않게 되었다.
> 하지만 실행 시에 바이트 코드를 기계어로 번역하는 작업 때문에 성능이 느려졌다. 그래서 이러한 문제를 해결하고자 바이트 코드를 기계어로 컴파일하는 
> JIT 컴파일러를 도입하여 사용하고 있다. JIT 컴파일러의 목표는 빠른 컴파일 및 특정 환경에 맞춤화된 최적화를 제공하는 것이며, 이를 위해 실행 프로파일 정보를 활용한다.
> 
> **JIT 컴파일러의 등장**
> Java 1.3부터는 Hotspot VM이 추가되었고, Hotspot VM 에는 2개의 JIT 컴파일러가 포함되어 있다.  
> c1
> * 클라이언트 컴파일러(Client Compiler)
> * 코드 최적화는 덜하지만 즉시 시작되는 속도는 빠름
> * 즉시 실행되는 데스크톱 애플리케이션 등에 적합함
> 
> c2  
> * 서버 컴파일러(Server Compiler)
> * 즉시 시작되는 속도는 느리지만 최적화는 많이 되어 warm-up 후에는 빠름
> * 장기 실행되는 서버 애플리케이션 등에 적합함
> 
> Hotspot VM은 초기 컴파일에 C1 컴파일러를 사용한다. 하지만 Hotspot VM은 각 메소드의 호출 여부를 계속해서 주시하고, 호출 횟수가 증가하면 해당 메소드를 재컴파일 하는데, 
> 이번에는 C2 컴파일러를 사용한다. 이를 계층형 컴파일(Tiered Compliation)이라고도 한다.
> HotSpot은 99년도에 나왔고, 오랜 연구 결과 끝에 많은 최적화가 구현되어 있다. C2 컴파일러는 극도로 최적화가 많이 되어 있어서 컴파일 언어를 능가하는 성능을 보여주기도 한다. 
> 최적화에는 프로파일링을 통해 얻은 정보들(디바이스 정보, 클럭 수 등)이 사용되며, 자바의 성능 향상은 이러한 프로파일링을 통해 얻어낸 정보를 바탕으로 하는 JIT 컴파일러의 최적화 역할이 크다.
> 하지만 반대로 이로 인해 애플리케이션이 초기에 느리게 실행되는 웜업 문제가 발생하기도 한다.
> 
> **JIT 컴파일러의 한계**
> 하지만 문제는 HotSpot VM의 C2 컴파일러가 한계에 직면했다는 것이다. C2 컴파일러는 일단 C++로 작성되어 개발자를 구하기도 어렵고, 상당히 오래된 만큼 복잡하다. 
> 이러한 이유로 최근 몇 년 동안 개발된 중요한 최적화가 없었을 뿐만 아니라 전문가들 역시 유지보수가 어렵다고 판단하였다. 즉, C2 컴파일러가 이제 End-of-life 에 직면한 것이다.
> * C++ 개발자를 구하기 어려움
> * 오래된 만큼 상당히 복잡함
> * 최근에 중요한 최적화가 거의 없었음
>
> 그래서 최적화가 더 이상 어려운 코드들은 HotSpotInstrinsicCandidate 어노테이션을 붙이도록 하는 작업들도 진행되었다. 
> 한계에 마주한 상황을 인정하고 애노테이션으로 명시해두는 것이다.
> JIT 컴파일러는 느리지 않으며, 오히려 엄청난 최적화로 인해 컴파일된 언어보다 뛰어난 성능을 보이기도 한다. 
> 대신 더 이상 유지보수하기 어려운 한계에 직면한 상황이다. 그래서 이에 대한 대안으로 등장한 것이 바로 GraalVM이다.

### GraalVM 의 등장과 아키텍처
>  GraalVM은 Oracle JDK가 아닌 OpenJDK8을 기반으로 만들어졌으며, 이는 새로운 단독 프로젝트가 아닌 기존의 HotSpot VM을 개선하고, 다양한 기능을 추가한 것임을 의미한다. 
> 그 중에서 GraalVM은 JIT 컴파일러들 중에서 기존의 c++로 작성된 C2 컴파일러인 Graal 컴파일러를 Java 기반으로 새롭게 작성하였다. 
> 즉, 자바로 만든 자바(Java on Java) 또는 자바로 만든 자바 컴파일러와 같은 수식어로 GraalVM을 설명할 수 있다.
> 
> GraalVM은 크게 아래의 3가지 특징을 갖고 있다고 볼 수 있으며, 이는 GraalVM의 아키텍처를 통해 그 이유를 알 수 있다.
> * 고성능 자바(High-Performance)
> * 다양한 언어의 통합(Polyglot)
> * Native 지원을 통한 빠른 start-up(Native Image)

### AOT 컴파일
> **정의**
> * AOT Compile 은 Ahead-Of-Time compile (사전 컴파일) 의 약자이다.
> * JIT(Just-In-Time) 컴파일과 주로 비교된다.
> * 프로그램 실행 중 즉시 변환을 수행하는 JIT(Just-In-Time) 컴파일과 대조적이다.
> * 고수준의 소스 코드를 네이티브 머신 코드로 미리 변환하는 프로세스를 의미한다.
> 
> **AOT 컴파일의 장점**
> * 시작 속도: 기계어로 사전 컴파일 되어 있어 시작이 빠르다. 런타임 환경에서 바이트 코드를 네이티브 코드로 변경할 필요가 없다.  
> * 예측 가능한 성능: AOT 컴파일된 앱은 보다 일관되고 예측 가능한 런타임 성능을 제공한다. JIT 컴파일은 런타임 중에 발생하는 컴파일 단계로 인해 가변 오버헤드가 발생할 수 있기 때문이다.  
> * 코드 난독화: 바이트 코드보다 리버스 엔지니어링이 더 어려워진다.
> * 리소스 효율: CPU 와 메모리 사용량 측면에서 더 효율적이다. JIT 과 비교해 런타임 컴파일 프로세스가 없으므로 앱의 오버헤드가 줄어든다.
> * 런타임 컴파일러 필요 없음: 런타임 컴파일러를 탑재할 필요가 없어 앱의 크기와 복잡성이 줄어든다.
> * 최적의 코드 경로: JIT 에서 수행하기에 비현실적인 공격적인 최적화를 수행한다.
> * 크로스 플랫폼 호환성: 다양한 대상 플랫폼용 실행 파일을 더 쉽게 생성할 수 있다.

### JIT vs AOT 
> 이제 바이트 코드 컴파일이 작동하는 방식과 두 가지 주요 전략(JIT 및 AOT)을 이해했으므로 어떤 접근 방식을 사용하는 것이 가장 좋은지 궁금할 것입니다. 
> 불행히도 대답은 예상대로 "그때 그때 다릅니다."
> 
> JIT 컴파일러는 프로그램을 크로스 플랫폼으로 만들어줍니다(즉, 플랫폼에 독립적이라는 의미). 실제로 “한번만 작성하면 어디에서나 실행 할 수 있다” 라는 슬로건은 
> 90년대 후반에 Java를 대중적인 언어로 만든 기능 중 하나였습니다. 
> JIT 컴파일러는 동시 가비지 컬렉터를 사용하여 최대 처리량 조건에서 메모리 회복력을 높여 STW(Stop the World)를 짧게 가져갑니다.
> 
> 반면에 AOT 컴파일러는 프로그램을 보다 효율적으로 실행하며, 이는 특히 클라우드 애플리케이션에 적합합니다. 
> 네이티브 이미지는 더 빠른 시작 속도를 제공하므로 애플리케이션의 부팅 시간이 단축되고, 이는 클라우드 서비스의 Scale-out이 더욱 간편해지게 만듭니다. 
> 또한, 클라우드에서 실행되는 Docker 컨테이너로 초기화된 마이크로서비스의 경우에 특히 유용합니다. 
> 사용되지 않는 코드의 완전한 제거(클래스, 필드, 메서드, 분기) 덕분에 파일의 크기가 작아지기 때문에 결과적으로 컨테이너의 이미지도 작아집니다. 
> 또한, 메모리 소비가 적기 때문에 동일한 메모리로 더 많은 컨테이너를 실행할 수 있으므로 클라우드 서비스의(AWS, GCP와 같은) 비용도 절감됩니다.
>
> 일반적으로 OpenJDK 에는 GraalVM 의 Native Image와 같은 AOT 컴파일러가 내장되어 있지 않습니다. 
> GraalVM은 특별히 AOT 컴파일을 위해 설계된 Oracle Labs의 프로젝트 중 하나입니다. GraalVM은 OpenJDK와 호환되면서도 몇 가지 추가 기능을 제공하는 특별한 배포입니다.
> 
> 만약 OpenJDK를 사용하고 있고, 특히 AOT 컴파일이 필요하다면 GraalVM을 설치하고 사용하는 것이 좋습니다. 
> GraalVM은 OpenJDK 기반으로 만들어져 있기 때문에 기존의 Java 어플리케이션을 호환성 있게 실행할 수 있으며, AOT 컴파일러를 통해 성능 향상을 얻을 수 있습니다.  

### 참조사이트
> [Java에서의 AOT vs JIT 컴파일](https://shirohoo.github.io/backend/java/2022-07-16-aot-vs-jit-in-java/)  
> [[Java] Hotspot VM의 한계와 이를 극복하기 위한 GraalVM의 등장](https://mangkyu.tistory.com/301)  
> [제이크서 위키 블로그:티스토리](https://jake-seo-dev.tistory.com/636)  

---

## 마이크로벤치마킹과 통계
### 자바 성능 측정 기초
> JIT 컴파일러는 코드를 조금이라도 효율적으로 작동시키려고 호출 계층을 최적화하므로 벤치마크 성능은 갭처 타이밍에 따라 달라진다.  
> 성능 측정 시 타이밍을 캡처하기 전에 JVM 이 가동 준비를 마칠 수 있게 웜업 기간을 두는 게 좋다. 보통 타이밍 세부를 캡처하지 않는 상태로 벤치마크
> 대상 코드를 여려 번 반복 실행하는 식으로 JVM 을 예열시킨다.
>
> 또 한 가지 고려할 외부 요인은 가비지 수집이다. 타이밍 캡처 도중에 GC 가 안 일어나게 설정한 다음 가동시키면 참 좋겠지만, 가비지 수집은 원래 불확정적
> 이어서 사람 마음대로 어찌할 도리가 없다.
> 가비지 수집이 작동되는 모습은 다음 VM 플래그를 추가하면 엿볼 수 있다.
> ```shell
> java -verbose:gc <Java Program>
> ```
>
> **Tip**
> * 시스템 전체를 벤치마크한다. 저수준 수치는 수집하지 않거나 그냥 무시한다.
> * 작은 자바 코드 조각보다 자바 애플리케이션 전체를 대상으로 성능 분석을 하는 편이 거의 항상 더 수월하다.
> * 여러분이 OpenJDK 나 범용 라이브러리 개발자라면 마땅히 마이크로벤치마킹이 필요하겠지만, 일반 개발자 입장에서는 시스템 성능 요건이 정말 마이크로벤치마크를 고려해야 할 정도인지 확실치 않을 것이다.

### JMH
> JMH 는 자바를 비롯해 JVM 을 타킷으로 하는 언어로 작성된 나노/마이크로/밀리/매크로 벤치마크를 제작, 실행, 분석하는 자바 도구이다.
>
> 정확한 벤치마킹 결과를 위해서 JMH 는 블랙홀 이라는 장치를 이용해서 벤치마크할 로직을 JVM 최적화로 부터 보호한다.
>
> 벤치마크가 통제된 환경을 나타낸다고 쉽게 가정하지만 실은 전혀 그렇지 못한 경우도 많다. 통제되지 않은 변수는 대개 찾아내기가 어려워서 JMH 같은 툴을 쓰더라도
> 각별히 잘 살펴야 한다.

### 정규 분포
> 정규 분포는 종 모양의 곡선으로, 평균 주위에 대부분의 데이터가 모여 있는 형태를 나타냅니다. 이 분포는 평균과 표준 편차라는 두 매개변수에 의해 완전히 정의됩니다.
> `평균 (Mean)`: 데이터의 평균값을 나타냅니다. 정규 분포의 중심이 되는 지점이며, 곡선의 정점이기도 합니다.  
> `표준 편차 (Standard Deviation)`: 데이터가 얼마나 평균 주위에 모여있는지를 나타내는 측도입니다. 표준 편차가 작을수록 데이터가 평균 주위에 모여있는 것이고, 표준 편차가 클수록 데이터가 흩어져 있는 것입니다.  
> 
> 정규 분포의 특징은 다음과 같습니다:
> * 대부분의 데이터는 평균 주위에 모여 있습니다.
> * 평균에서 멀어질수록 데이터의 빈도가 감소합니다.
> * 평균에서 표준 편차의 배수만큼 떨어진 곳에서의 빈도가 정해진 법칙에 따라 나타납니다.

### 비정규 분포
> 비정규 분포는 정규 분포의 특징을 따르지 않는 확률 분포를 말합니다. 정규 분포와는 달리 비정규 분포는 종 모양의 대칭적인 형태가 아닐 수 있으며, 데이터의 분포가 왜곡되거나 비대칭일 수 있습니다. 
> 다양한 비정규 분포가 있지만, 몇 가지 대표적인 예시를 살펴보겠습니다.
> * 균등 분포 (Uniform Distribution): 모든 값이 동일한 확률로 나타나는 분포를 말합니다. 이는 주사위를 굴렸을 때 나오는 눈금의 분포와 비슷한 개념입니다.
> * 지수 분포 (Exponential Distribution): 주어진 시간 내에 어떤 사건이 발생할 때까지 걸리는 시간을 나타내는 분포로, 지수 함수의 형태를 가지고 있습니다. 주로 사건 간격이나 수명과 관련된 분포로 사용됩니다.
> * 파레토 분포 (Pareto Distribution): 상대적으로 적은 수의 사건이 매우 빈번하게 발생하는 분포를 나타냅니다. 상위 높은 빈도를 가진 소수의 원소들이 전체 현상의 대다수를 차지하는 경우에 많이 나타납니다.
> * 슈퍼노바 분포 (Power Law Distribution): 일부 사건이 다른 사건보다 훨씬 자주 발생하는 분포를 말합니다. 인터넷에서의 웹페이지 방문 횟수나 도시의 인구 분포 등에서 발견될 수 있습니다.
> * 긴 꼬리형 비정규 분포는 어떤 사건이 매우 드물게 발생하지만 극단적인 값이 발생할 가능성이 있는 확률 분포를 나타냅니다.   
> 이는 주로 슈퍼노바 분포나 파레토 분포와 같이 일부 사건이 다른 사건보다 훨씬 높은 빈도로 발생하는 상황에서 나타납니다.  
> 긴 꼬리형 분포는 두 가지 주요 특징을 가지고 있습니다:  
> 꼬리가 길다 (Long Tail): 분포의 꼬리 부분이 정규 분포보다 더 늘어져 있습니다. 이는 극단적인 값이 나타날 가능성이 높음을 의미합니다.  
> 절단되지 않은 분포 (Uncut Distribution): 일반적으로 분포의 꼬리 부분이 잘린 것이 아니라, 극단적인 값이 발생할 수 있는 확률이 존재합니다.  
> 긴 꼬리형 분포의 예시로는 온라인 서비스에서의 이용자 행동 데이터, 출판물의 판매량, 인터넷 검색어 사용 빈도 등이 있습니다.   
> 이러한 분포에서는 소수의 사건이 다수의 사건을 훨씬 능가하는 경우가 흔하며, 상대적으로 드문 사건이 큰 영향을 미칠 수 있습니다.  

### JVM 성능 통계
> 모든 측정은 어느 정도의 오차를 수반한다. 자바 개발자가 성능 분석 시 흔히 맞닥뜨리는 두 가지 주요 오차 유형은 다음과 같다.   
> * 랜덤 오차(Random error): 측정 오차 또는 무관계 요인이 어떤 상관관계 없이 결과에 영향을 미친다.  
> * 계통 오차(Systematic error): 원인을 알 수 없는 요인이 상관관계 있는 형태로 측정에 영향을 미친다.  
> 
> 정확도(Accuracy)는 계통 오차(Systematic error)의 수준을 나태내는 용어로, 정확도가 높으면 계통 오차가 낮은 것이다.  
> 정밀도(Precision)는 랜덤 오차를 나타내는 용어로서, 정밀도가 높으면 랜덤 오차가 낮은 것이다.  
> 
> 랜덤 오차는 원인을 알 수 없는, 또는 예기치 못한 환경상의 변화 때문에 일어난다. 기초과학 실험에서는 그런 변화가 측정 장비나 환경 자체에서 일어나지만, 소프트웨어에서는
> 측정 툴을 못 믿을 이유가 없으므로 랜덤 오차의 근원은 오직 운영 환경뿐이다.  
> 랜덤 오차는 대부분 정규 분포(가우시안 분포)를 따른다. 정규 분포는 오차가 측정값에 미치는 긍정적/부정적 영향도가 얼추 비슷한 경우에는 적합하지만 JVM 에는
> 이 모델이 잘 맞지 않는다.
> 
> `메서드 타이밍`: 메서드 실행 시간을 재는(기록하는) 행위.  

---

