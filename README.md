# java-optimization

## 성능과 최적화
### 성능은 실험과학이다.
> 성능은 다음과 같은 활동을 하면서 원하는 결과를 얻기 위한, 일종의 실험과학이라고 볼 수 있다.  
> * 원하는 결과를 정의한다.
> * 기존 시스템을 측정한다.
> * 요건을 충족시키려면 무슨 일을 해야 할지 정한다.
> * 개선 활동을 추진한다.
> * 다시 테스트한다.
> * 목표가 달성됐는지 판단한다. 

### 성능 분류
> **처리율(throughput)**  
> 처리율은 시스템이 수행 가능한 작업 비율을 나타낸 지표이다. 보통 일정 시간 동안 완료한 작업 단위 수로 표시한다.(예: 초당 처리 가능한 트랜잭션 수 TPS)  
> 처리율이 실제 성능을 반영하는 의미 있는 지표가 되려면 수치를 얻은 기준 플랫폼에 대해서도 내용을 기술해야 한다. 
> * 하드웨어 스펙
> * OS
> * 소프트웨어 스택
> * 테스트한 시스템의 환경: 단일/클러스터
> * 워크로드(작업 할당량)
> 
> **지연(latency)**  
> 하나의 트랜잭션을 처리하고 그 결과를 응답받았을 때까지의 소요된 시간.
> 
> **용량(capacity)**  
> 용량은 시스템이 보유한 작업 병렬성의 총량, 즉 시스템이 동시 처리 가능한 작업 단위(즉, 트랜잭션) 개수를 말한다.  
> 
> **사용률(utilization)**  
> 성능 분석 업무 중 가장 흔한 태스크는 시스템 리소스를 효율적으로 활용하는 것이다. 
> 
> **효율(efficiency)**  
> 전체 시스템의 효율은 처리율을 리소스 사용률로 나눈 값으로 측정한다.
> 
> **확장성(scalability)**  
> 처리율이나 시스템 용량은, 처리하는 데 끌어 쓸 수 있는 리소스에 달려 있다. 리소스 추가에 따른 처리율 변화는 시스템/애플리케이션의 확장성을 가늠하는 척도이다.  
> 시스템 확장성은 궁극적으로는 정확히 리소스를 투입한 만큼 처리율이 변경되는 형태를 지향한다.
> 
> **저하(degradation)**  
> 시스템이 더 많은 부하를 받으면 지연 그리고 처리율 측정값에 변화가 생긴다. 시스템을 덜 사용하고 있으면 측정값이 느슨하게 변하지만, 
> 시스템이 풀 가동된 상태면 처리율이 더는 늘어나지 않는, 즉 지연이 증가하는 양상을 띤다. 이런 현상을 부하 증가에 따른 저하라고 한다.  

---

## JVM 이야기
### Hotspot VM 과 JIT(Just In Time) 컴파일러
> **C 언어의 동작 방식**
> C, C++, GoLang, Rust 등과 같은 컴파일 언어는 컴파일 과정에서 바로 기계어로 번역하고 실행 파일을 만들어낸다. 
> 그리고 컴파일 시에 코드 최적화까지 진행하여 처리 성능이 상당히 뛰어나다. 대신 생성된 기계어가 빌드 환경(CPU 아키텍처)에 종속적이라서, 플랫폼이 바뀐다면 다시 빌드해야 하는 문제가 있다.
> 
> **Java 언어의 동작 방식**  
> 자바는 이러한 플랫폼 종속적인 문제를 해결하고자 JVM을 도입하였고, 그래서 동작 과정이 조금 다르다.
> 만약 우리가 자바 애플리케이션을 실행한다고 하면, 자바 코드는 먼저 바이트 코드로 컴파일된다. 바이트 코드는 자바 코드보다 간결하고 간단하지만, 
> 0과 1만 이해할 수 있는 컴퓨터는 이를 읽어들일 수 없다. 바이트 코드는 JVM 을 위한 중간 언어인 것이다. 따라서 JVM 은 애플리케이션이 실행되면서 읽어들인 
> 바이트 코드를 실시간으로 기계어로 번역하고, CPU 가 번역된 기계어를 처리한다. 이러한 구조 덕분에 Java 는 플랫폼에 종속되지 않게 되었다.
> 하지만 실행 시에 바이트 코드를 기계어로 번역하는 작업 때문에 성능이 느려졌다. 그래서 이러한 문제를 해결하고자 바이트 코드를 기계어로 컴파일하는 
> JIT 컴파일러를 도입하여 사용하고 있다. JIT 컴파일러의 목표는 빠른 컴파일 및 특정 환경에 맞춤화된 최적화를 제공하는 것이며, 이를 위해 실행 프로파일 정보를 활용한다.
> 
> **JIT 컴파일러의 등장**
> Java 1.3부터는 Hotspot VM이 추가되었고, Hotspot VM 에는 2개의 JIT 컴파일러가 포함되어 있다.  
> c1
> * 클라이언트 컴파일러(Client Compiler)
> * 코드 최적화는 덜하지만 즉시 시작되는 속도는 빠름
> * 즉시 실행되는 데스크톱 애플리케이션 등에 적합함
> 
> c2  
> * 서버 컴파일러(Server Compiler)
> * 즉시 시작되는 속도는 느리지만 최적화는 많이 되어 warm-up 후에는 빠름
> * 장기 실행되는 서버 애플리케이션 등에 적합함
> 
> Hotspot VM은 초기 컴파일에 C1 컴파일러를 사용한다. 하지만 Hotspot VM은 각 메소드의 호출 여부를 계속해서 주시하고, 호출 횟수가 증가하면 해당 메소드를 재컴파일 하는데, 
> 이번에는 C2 컴파일러를 사용한다. 이를 계층형 컴파일(Tiered Compliation)이라고도 한다.
> HotSpot은 99년도에 나왔고, 오랜 연구 결과 끝에 많은 최적화가 구현되어 있다. C2 컴파일러는 극도로 최적화가 많이 되어 있어서 컴파일 언어를 능가하는 성능을 보여주기도 한다. 
> 최적화에는 프로파일링을 통해 얻은 정보들(디바이스 정보, 클럭 수 등)이 사용되며, 자바의 성능 향상은 이러한 프로파일링을 통해 얻어낸 정보를 바탕으로 하는 JIT 컴파일러의 최적화 역할이 크다.
> 하지만 반대로 이로 인해 애플리케이션이 초기에 느리게 실행되는 웜업 문제가 발생하기도 한다.
> 
> **JIT 컴파일러의 한계**
> 하지만 문제는 HotSpot VM의 C2 컴파일러가 한계에 직면했다는 것이다. C2 컴파일러는 일단 C++로 작성되어 개발자를 구하기도 어렵고, 상당히 오래된 만큼 복잡하다. 
> 이러한 이유로 최근 몇 년 동안 개발된 중요한 최적화가 없었을 뿐만 아니라 전문가들 역시 유지보수가 어렵다고 판단하였다. 즉, C2 컴파일러가 이제 End-of-life 에 직면한 것이다.
> * C++ 개발자를 구하기 어려움
> * 오래된 만큼 상당히 복잡함
> * 최근에 중요한 최적화가 거의 없었음
>
> 그래서 최적화가 더 이상 어려운 코드들은 HotSpotInstrinsicCandidate 어노테이션을 붙이도록 하는 작업들도 진행되었다. 
> 한계에 마주한 상황을 인정하고 애노테이션으로 명시해두는 것이다.
> JIT 컴파일러는 느리지 않으며, 오히려 엄청난 최적화로 인해 컴파일된 언어보다 뛰어난 성능을 보이기도 한다. 
> 대신 더 이상 유지보수하기 어려운 한계에 직면한 상황이다. 그래서 이에 대한 대안으로 등장한 것이 바로 GraalVM이다.

### GraalVM 의 등장과 아키텍처
>  GraalVM은 Oracle JDK가 아닌 OpenJDK8을 기반으로 만들어졌으며, 이는 새로운 단독 프로젝트가 아닌 기존의 HotSpot VM을 개선하고, 다양한 기능을 추가한 것임을 의미한다. 
> 그 중에서 GraalVM은 JIT 컴파일러들 중에서 기존의 c++로 작성된 C2 컴파일러인 Graal 컴파일러를 Java 기반으로 새롭게 작성하였다. 
> 즉, 자바로 만든 자바(Java on Java) 또는 자바로 만든 자바 컴파일러와 같은 수식어로 GraalVM을 설명할 수 있다.
> 
> GraalVM은 크게 아래의 3가지 특징을 갖고 있다고 볼 수 있으며, 이는 GraalVM의 아키텍처를 통해 그 이유를 알 수 있다.
> * 고성능 자바(High-Performance)
> * 다양한 언어의 통합(Polyglot)
> * Native 지원을 통한 빠른 start-up(Native Image)

### AOT 컴파일
> **정의**
> * AOT Compile 은 Ahead-Of-Time compile (사전 컴파일) 의 약자이다.
> * JIT(Just-In-Time) 컴파일과 주로 비교된다.
> * 프로그램 실행 중 즉시 변환을 수행하는 JIT(Just-In-Time) 컴파일과 대조적이다.
> * 고수준의 소스 코드를 네이티브 머신 코드로 미리 변환하는 프로세스를 의미한다.
> 
> **AOT 컴파일의 장점**
> * 시작 속도: 기계어로 사전 컴파일 되어 있어 시작이 빠르다. 런타임 환경에서 바이트 코드를 네이티브 코드로 변경할 필요가 없다.  
> * 예측 가능한 성능: AOT 컴파일된 앱은 보다 일관되고 예측 가능한 런타임 성능을 제공한다. JIT 컴파일은 런타임 중에 발생하는 컴파일 단계로 인해 가변 오버헤드가 발생할 수 있기 때문이다.  
> * 코드 난독화: 바이트 코드보다 리버스 엔지니어링이 더 어려워진다.
> * 리소스 효율: CPU 와 메모리 사용량 측면에서 더 효율적이다. JIT 과 비교해 런타임 컴파일 프로세스가 없으므로 앱의 오버헤드가 줄어든다.
> * 런타임 컴파일러 필요 없음: 런타임 컴파일러를 탑재할 필요가 없어 앱의 크기와 복잡성이 줄어든다.
> * 최적의 코드 경로: JIT 에서 수행하기에 비현실적인 공격적인 최적화를 수행한다.
> * 크로스 플랫폼 호환성: 다양한 대상 플랫폼용 실행 파일을 더 쉽게 생성할 수 있다.

### JIT vs AOT 
> 이제 바이트 코드 컴파일이 작동하는 방식과 두 가지 주요 전략(JIT 및 AOT)을 이해했으므로 어떤 접근 방식을 사용하는 것이 가장 좋은지 궁금할 것입니다. 
> 불행히도 대답은 예상대로 "그때 그때 다릅니다."
> 
> JIT 컴파일러는 프로그램을 크로스 플랫폼으로 만들어줍니다(즉, 플랫폼에 독립적이라는 의미). 실제로 “한번만 작성하면 어디에서나 실행 할 수 있다” 라는 슬로건은 
> 90년대 후반에 Java를 대중적인 언어로 만든 기능 중 하나였습니다. 
> JIT 컴파일러는 동시 가비지 컬렉터를 사용하여 최대 처리량 조건에서 메모리 회복력을 높여 STW(Stop the World)를 짧게 가져갑니다.
> 
> 반면에 AOT 컴파일러는 프로그램을 보다 효율적으로 실행하며, 이는 특히 클라우드 애플리케이션에 적합합니다. 
> 네이티브 이미지는 더 빠른 시작 속도를 제공하므로 애플리케이션의 부팅 시간이 단축되고, 이는 클라우드 서비스의 Scale-out이 더욱 간편해지게 만듭니다. 
> 또한, 클라우드에서 실행되는 Docker 컨테이너로 초기화된 마이크로서비스의 경우에 특히 유용합니다. 
> 사용되지 않는 코드의 완전한 제거(클래스, 필드, 메서드, 분기) 덕분에 파일의 크기가 작아지기 때문에 결과적으로 컨테이너의 이미지도 작아집니다. 
> 또한, 메모리 소비가 적기 때문에 동일한 메모리로 더 많은 컨테이너를 실행할 수 있으므로 클라우드 서비스의(AWS, GCP와 같은) 비용도 절감됩니다.
>
> 일반적으로 OpenJDK 에는 GraalVM 의 Native Image와 같은 AOT 컴파일러가 내장되어 있지 않습니다. 
> GraalVM은 특별히 AOT 컴파일을 위해 설계된 Oracle Labs의 프로젝트 중 하나입니다. GraalVM은 OpenJDK와 호환되면서도 몇 가지 추가 기능을 제공하는 특별한 배포입니다.
> 
> 만약 OpenJDK를 사용하고 있고, 특히 AOT 컴파일이 필요하다면 GraalVM을 설치하고 사용하는 것이 좋습니다. 
> GraalVM은 OpenJDK 기반으로 만들어져 있기 때문에 기존의 Java 어플리케이션을 호환성 있게 실행할 수 있으며, AOT 컴파일러를 통해 성능 향상을 얻을 수 있습니다.  

### 참조사이트
> [Java에서의 AOT vs JIT 컴파일](https://shirohoo.github.io/backend/java/2022-07-16-aot-vs-jit-in-java/)  
> [[Java] Hotspot VM의 한계와 이를 극복하기 위한 GraalVM의 등장](https://mangkyu.tistory.com/301)  
> [제이크서 위키 블로그:티스토리](https://jake-seo-dev.tistory.com/636)  
